{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dogoGPT Training\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Kinyugo/dogoGPT.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd dogoGPT\n",
    "%pip install -q -r notebook_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt # shakespeare\n",
    "!wget https://raw.githubusercontent.com/Kinyugo/Walks_Into_A_Bar_Language_Model/master/data/walks_into_a_bar.txt -O bar_jokes.txt # bar jokes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from dogogpt.configs import TrainingConfig\n",
    "from dogogpt.language_model import LanguageModel\n",
    "from dogogpt.training import run_training\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_config = {\n",
    "    \"datamodule\": {\n",
    "        \"src_path\": \"shakespeare.txt\",\n",
    "        \"num_chars\": 256,\n",
    "        \"batch_size\": 32,\n",
    "        \"num_workers\": 2,\n",
    "        \"pin_memory\": True,\n",
    "    },\n",
    "    \"lit_language_model\": {\"sample_every_n_steps\": 1000},\n",
    "    \"trainer\": {\"max_steps\": 10001},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = OmegaConf.structured(TrainingConfig)\n",
    "custom_config = OmegaConf.create(dict_config)\n",
    "config = OmegaConf.merge(default_config, custom_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training(config)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lm = LanguageModel.from_pretrained(ckpt_path, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"\\n\"]\n",
    "samples = lm(\n",
    "    prompts,\n",
    "    num_tokens=512,\n",
    "    context_size=256,\n",
    "    temperature=1.0,\n",
    "    top_k=None,\n",
    "    num_parallel_tokens=1,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = \"-\" * 20\n",
    "print(f\"\\n{separator}\\n\".join(samples))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
